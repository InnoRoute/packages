//*****************************************************************************************************************
/**
*push new packet into TX descriptor ring
*@param *datalength length of data in memory
*@param *dma_addr dma-address of packet buffer
*@param eof last_packet?
*@param port trustnode output-port 0..15
*@param ll local loop (send to cpu)
*/
int
INR_TX_push (struct sk_buff *skb, uint8_t * data, uint16_t * datalength, uint8_t eof, uint8_t port,uint8_t ll)
{
//INR_LOG_debug("TX_current:%i  TX_unmap_current:%i  Datapointer:%llx\n",INR_PCI_tx_descriptor_current,INR_PCI_tx_descriptor_unmap_current,data);
//FPGA reads from head, we push at bottom...
data_tx[INR_PCI_tx_descriptor_current]=skb;
  uint64_t dma_addr = dma_map_single (&globdev->dev, data, datalength, DMA_TO_DEVICE);	//map packet  to DMA
  if (dma_mapping_error (&globdev->dev, dma_addr))
    INR_LOG_debug ("TX dma mappng error! current:%i \n",INR_PCI_tx_descriptor_current);
//INR_LOG_debug("Map Packet to dma: %llx to %llx\n",data,dma_addr);
/*
INR_LOG_debug("TX:");
uint16_t tmp;
for (tmp=0;(tmp<datalength);tmp++){printk("%x ",data[tmp]);if(tmp%20==0)printk("\n");}
printk("\n");
*/
  struct INR_PCI_tx_descriptor *TX_descriptor = INR_PCI_tx_descriptor_ring[INR_PCI_tx_descriptor_current];	//create temp. TDESC-structure
  //INR_LOG_debug ("current descriptor offset:%i\n",             INR_PCI_tx_descriptor_current);
//INR_LOG_debug("TX_current:%i, length:%i\n",INR_PCI_tx_descriptor_current,datalength);
  if ((TX_descriptor->STA & 0x1) == 0)	//look for DD-Bit
    {
      INR_LOG_debug ("error descriptor not free\n");
      return 1;			//descriptor is not free, abort
    }
  if (TX_descriptor->buffer)
    {				//if there is an address stored, first unmap before override
      //INR_LOG_debug ("unmap old packet\n");
      dma_unmap_single (&globdev->dev, TX_descriptor->buffer, TX_descriptor->length, DMA_TO_DEVICE);	//unmap DMA
	kfree(data_tx[INR_PCI_tx_descriptor_current]);
      //dev_kfree_skb (data_tx[INR_PCI_tx_descriptor_current]);//free skb
      //INR_TX_unmap(TX_descriptor->buffer,TX_descriptor->length);
      //kthread_run(&INR_TX_unmap,TX_descriptor,"txunmap");
    }
data_tx[INR_PCI_tx_descriptor_current]=data;
//data_tx[INR_PCI_tx_descriptor_current]=skb;//save skb for later
  //INR_LOG_debug ("fill TX-descriptor\n");
  TX_descriptor->buffer = cpu_to_le64(dma_addr);	//store address of packet in descriptor-ring
  TX_descriptor->length = datalength;
  TX_descriptor->CSO = 0x00;
  TX_descriptor->CMD = (1 & eof) | ((1 & ll) << 7);	//send eof and to-cpu-bit
  TX_descriptor->STA = 0x0;
  TX_descriptor->Rsvd = 0xf & port;	//triger output-port
  TX_descriptor->CSS = 0x00;
  TX_descriptor->VLAN = 0;
  //INR_PRINT_DESC_status (globdev, INR_PCI_tx_descriptor_current);
  //INR_LOG_debug ("update TX-Ring bottom\n");

  if (INR_PCI_tx_descriptor_current ==
      (INR_PCI_tx_descriptor_ring_length - 1))
    {
      INR_PCI_tx_descriptor_current = 0;
    }
  else
    {
      INR_PCI_tx_descriptor_current++;
    }				//increment INR_PCI_tx_descriptor_current
  if (eof)
    {
      INR_PCI_BAR0_write ((INR_PCI_tx_descriptor_length * (INR_PCI_tx_descriptor_current)), INR_PCI_tx_descriptor_tail_reg);	//store address-offset of this last written descriptor in bar0
      //INR_LOG_debug ("TX_Ring_Bottom:%x\n",INR_PCI_BAR0_read (INR_PCI_tx_descriptor_tail_reg));
      wake_up_interruptible (&INR_PCI_TX_unmapd_waittingqueu);	//wakeup TX_unmap_d
    }

  return 0;
}


//*****************************************************************************************************************
/**
*Processing rx-descriptor-ring
*@param index RX-descriptor-ring-index
*/
void
INR_PCI_process_rx_descriptor_ring (uint8_t index)
{

switch (index){
case 0:down(&INR_PCI_rx_ring_sem0);break;
case 1:down(&INR_PCI_rx_ring_sem1);break;
case 2:down(&INR_PCI_rx_ring_sem2);break;
case 3:down(&INR_PCI_rx_ring_sem3);break;
case 4:down(&INR_PCI_rx_ring_sem4);break;
case 5:down(&INR_PCI_rx_ring_sem5);break;
case 6:down(&INR_PCI_rx_ring_sem6);break;
case 7:down(&INR_PCI_rx_ring_sem7);break;
case 8:down(&INR_PCI_rx_ring_sem8);break;
case 9:down(&INR_PCI_rx_ring_sem9);break;
case 10:down(&INR_PCI_rx_ring_sem10);break;
case 11:down(&INR_PCI_rx_ring_sem11);break;
case 12:down(&INR_PCI_rx_ring_sem12);break;
case 13:down(&INR_PCI_rx_ring_sem13);break;
case 14:down(&INR_PCI_rx_ring_sem14);break;
case 15:down(&INR_PCI_rx_ring_sem15);break;
default: break;
}
//INR_LOG_debug ("store eth-type in skb\n");
  while (INR_PCI_BAR0_read (INR_PCI_rx_descriptor_head_reg + (64 * index)) !=
	 (INR_PCI_rx_descriptor_current[index] *
	  INR_PCI_rx_descriptor_length))
    {
      struct INR_PCI_rx_descriptor *RX_descriptor =
	INR_PCI_rx_descriptor_ring[INR_PCI_rx_descriptor_current[index]]
	[index];

      dma_unmap_page (&globdev->dev,
		      dma_rx[INR_PCI_rx_descriptor_current[index]][index],
		      data_size_rx, DMA_FROM_DEVICE);
//dma_sync_single_range_for_cpu(&globdev->dev,dma_rx[INR_PCI_rx_descriptor_current[index]][index],0,data_size_rx, DMA_FROM_DEVICE);
     INR_LOG_debug("RX_Current:%i Status:%x Index:%i FirstPKG:%i Buffer:%llx DMA:%llx MEM:%llx\n",
	 INR_PCI_rx_descriptor_current[index], RX_descriptor->Status, index,
	 firstpkg[index], RX_descriptor->buffer,
	 dma_rx[INR_PCI_rx_descriptor_current[index]][index],
	 data_rx[INR_PCI_rx_descriptor_current[index]][index]);
      uint8_t offset = 0;
      if (firstpkg[index])
	{
//INR_PCI_rx_skb[index]->mac_header=data_rx[INR_PCI_rx_descriptor_current[index]][index];
		skb_put (INR_PCI_rx_skb[index], RX_descriptor->length);
	  memcpy (INR_PCI_rx_skb[index]->data , page_address (data_rx[INR_PCI_rx_descriptor_current[index]][index]), RX_descriptor->length);	//cp first bytes of mac-header in skb.. crashes 0cp!.. to be done later

/*	uint8_t i=0;
for(i=0;i<ETH_HLEN;i++)printk("%x ",page_address(data_rx[INR_PCI_rx_descriptor_current[index]][index])+i);
printk("\n");
*/
	  firstpkg[index] = 0;
	  offset = RX_descriptor->length;//ETH_HLEN;


	}else{
      skb_add_rx_frag (INR_PCI_rx_skb[index],
		       skb_shinfo (INR_PCI_rx_skb[index])->nr_frags,
		       data_rx[INR_PCI_rx_descriptor_current[index]][index],
		       offset, RX_descriptor->length - offset,
		       RX_descriptor->length - offset);
}
      uint8_t *tmpdata =
	page_address (data_rx[INR_PCI_rx_descriptor_current[index]][index]);
     /* INR_LOG_debug ("RX(%llx):",
		     page_address (data_rx
				   [INR_PCI_rx_descriptor_current[index]]
				   [index]));*/
 /*     uint16_t tmp;
      for (tmp = 0; (tmp < RX_descriptor->length)&&(tmp<10); tmp++)
	printk ("%x ", tmpdata[tmp]);
      printk ("\n");

*/


      if (RX_descriptor->Status & 0x2)	//end of paket or not?
	{



	  struct INR_NW_priv *priv = netdev_priv (get_nwdev (index));

	  priv->stats.rx_packets++;
	  priv->stats.rx_bytes += INR_PCI_rx_skb[index]->data_len;
	  //skb_reset_mac_header(INR_PCI_rx_skb[index]);
//INR_PCI_rx_skb[index]->pkt_type=PACKET_HOST;//PACKET_BROADCAST;//set pkt-typ
//INR_PCI_rx_skb[index]->protocol=htons(ETH_P_IP);
	  //
	  //INR_LOG_debug("len:%i data-len:%i\n",INR_PCI_rx_skb[index]->len,INR_PCI_rx_skb[index]->data_len);
	  //INR_PCI_rx_skb[index]->len+=ETH_HLEN;
	  INR_PCI_rx_skb[index]->protocol =
	    eth_type_trans (INR_PCI_rx_skb[index],
			    INR_PCI_rx_skb[index]->dev);
	  //INR_LOG_debug("len:%i data-len:%i\n",INR_PCI_rx_skb[index]->len,INR_PCI_rx_skb[index]->data_len);
	  //INR_LOG_debug("pkt-typ:%i\n",INR_PCI_rx_skb[index]->pkt_type);
	  INR_PCI_rx_skb[index]->ip_summed = CHECKSUM_UNNECESSARY;

	 // if (NET_RX_DROP == netif_rx (INR_PCI_rx_skb[index])) INR_LOG_debug ("PKT dropped :/\n");	//push to nw stack
	  INR_PCI_rx_skb[index] = netdev_alloc_skb (get_nwdev (index),data_size_rx);
	if(!INR_PCI_rx_skb[index])INR_LOG_debug("rx-error cant alloc skb\n");
	  INR_PCI_rx_skb[index]->dev = get_nwdev (index);
	  //skb_reserve(INR_PCI_rx_skb[index], 10);
	  //INR_PCI_rx_skb[index]->len=data_size_rx*2;
	  //skb_reset_mac_header(INR_PCI_rx_skb[index]);
	  //skb_reset_network_header(INR_PCI_rx_skb[index]);
	  //INR_PCI_rx_skb[index]->protocol = __constant_htons(ETH_P_AOE);
	  //skb_checksum_none_assert(INR_PCI_rx_skb[index]);
	  firstpkg[index] = 1;
	  /*INR_PCI_rx_skb[index]->protocol =eth_type_trans (INR_PCI_rx_skb[index],INR_PCI_rx_skb[index]->dev);
	     INR_PCI_rx_skb[index]->ip_summed = CHECKSUM_UNNECESSARY; */


	}

      data_rx[INR_PCI_rx_descriptor_current[index]][index] = alloc_pages (GFP_DMA, 0);	//alloc one page(will see if this is good ;))
      if (!data_rx[INR_PCI_rx_descriptor_current[index]][index])
	INR_LOG_debug ("alloc RX-Page faild\n");
      dma_rx[INR_PCI_rx_descriptor_current[index]][index] =
	dma_map_page (&globdev->dev,
		      data_rx[INR_PCI_rx_descriptor_current[index]][index], 0,
		      data_size_rx, DMA_FROM_DEVICE);

      if (dma_mapping_error
	  (&globdev->dev,
	   dma_rx[INR_PCI_rx_descriptor_current[index]][index]))
	INR_LOG_debug ("RX dma mappng error! current:%i index:%i\n",
		       INR_PCI_rx_descriptor_current[index], index);
      RX_descriptor->buffer = cpu_to_le64(dma_rx[INR_PCI_rx_descriptor_current[index]][index]);	// save memory address in descriptor
      RX_descriptor->length = data_size_rx;
      RX_descriptor->Status &= ~(0x3);	//status zur√ºcksetzen
      if (INR_PCI_rx_descriptor_current[index] ==
	  (INR_PCI_rx_descriptor_ring_length - 1))
	{
	  INR_PCI_rx_descriptor_current[index] = 0;
	}
      else
	{
	  INR_PCI_rx_descriptor_current[index]++;
	}			//increment INR_PCI_rx_descriptor_current
      //INR_PCI_BAR0_write ((INR_PCI_rx_descriptor_length * (INR_PCI_rx_descriptor_current)),INR_PCI_rx_descriptor_tail_reg);

      uint64_t bottmp =
	INR_PCI_BAR0_read (INR_PCI_rx_descriptor_tail_reg + (64 * index));
      if (bottmp ==
	  ((INR_PCI_rx_descriptor_ring_length -
	    1) * INR_PCI_rx_descriptor_length))
	{
	  INR_PCI_BAR0_write (0,
			      INR_PCI_rx_descriptor_tail_reg + (64 * index));
	}
      else
	{
	  INR_PCI_BAR0_write (bottmp + INR_PCI_rx_descriptor_length,
			      INR_PCI_rx_descriptor_tail_reg + (64 * index));
	}

    }
/*headskb->len=fullength;

//INR_HW_tx (headskb->data, headskb->len);
*/
//INR_LOG_debug ("push skb to net stack:%i %i\n",skb->data_len, skb->len);





switch (index){//semaphore freigeben
case 0:up(&INR_PCI_rx_ring_sem0);break;
case 1:up(&INR_PCI_rx_ring_sem1);break;
case 2:up(&INR_PCI_rx_ring_sem2);break;
case 3:up(&INR_PCI_rx_ring_sem3);break;
case 4:up(&INR_PCI_rx_ring_sem4);break;
case 5:up(&INR_PCI_rx_ring_sem5);break;
case 6:up(&INR_PCI_rx_ring_sem6);break;
case 7:up(&INR_PCI_rx_ring_sem7);break;
case 8:up(&INR_PCI_rx_ring_sem8);break;
case 9:up(&INR_PCI_rx_ring_sem9);break;
case 10:up(&INR_PCI_rx_ring_sem10);break;
case 11:up(&INR_PCI_rx_ring_sem11);break;
case 12:up(&INR_PCI_rx_ring_sem12);break;
case 13:up(&INR_PCI_rx_ring_sem13);break;
case 14:up(&INR_PCI_rx_ring_sem14);break;
case 15:up(&INR_PCI_rx_ring_sem15);break;
default: break;
}
}

